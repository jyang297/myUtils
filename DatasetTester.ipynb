{"cells":[{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["import os\n","from PIL import Image\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms\n","from torch.utils.tensorboard import SummaryWriter\n","import random\n","import numpy as np\n","\n"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["# import my new datasetloader here\n","from newX1000loader import X4K1000FPSDataset"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["seed = 12345 #56789 #1234\n","random.seed(seed)\n","np.random.seed(seed)\n","torch.manual_seed(seed)\n","torch.cuda.manual_seed_all(seed)\n","torch.backends.cudnn.benchmark = True"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","# Custom Dataset Class\n","class CustomImageDataset(Dataset):\n","    def __init__(self, root_dir, transform=None):\n","        self.root_dir = root_dir\n","        self.transform = transform\n","        self.image_groups = []\n","\n","        for subdir in os.listdir(root_dir):\n","            subdir_path = os.path.join(root_dir, subdir)\n","            if os.path.isdir(subdir_path):\n","                images = sorted(os.listdir(subdir_path))\n","                for i in range(0, len(images) - 2):\n","                    self.image_groups.append([os.path.join(subdir_path, images[i]),\n","                                              os.path.join(subdir_path, images[i+1]),\n","                                              os.path.join(subdir_path, images[i+2])])\n","\n","    def __len__(self):\n","        return len(self.image_groups)\n","\n","    def __getitem__(self, idx):\n","        image_paths = self.image_groups[idx]\n","        images = [Image.open(img_path).convert('RGB') for img_path in image_paths]\n","\n","        if self.transform:\n","            images = [self.transform(image) for image in images]\n","\n","        image_stack = torch.stack(images, dim=0)\n","        return image_stack\n","\n","# Transformation\n","transform = transforms.Compose([\n","    transforms.Resize((256, 256)),\n","    transforms.ToTensor()\n","])\n"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["\n","# Dataset and DataLoader\n","transform = transforms.Compose([\n","    transforms.ToTensor()  # Convert images to tensor after all other transformations\n","])\n","# dataset = X4K1000FPSDataset(root_dir='/home/jyzhao/Code/Datasets/X4K1000FPS', transform=transform)\n","dataset = X4K1000FPSDataset(root_dir='/home/jyzhao/Code/Datasets/X4K1000FPS', transform=transform, crop_size=(224, 224))\n","\n","dataloader = DataLoader(dataset, batch_size=1, shuffle=True)"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["................................................................................................................................................."]},{"ename":"RuntimeError","evalue":"Sizes of tensors must match except in dimension 0. Expected size 224 but got size 223 for tensor number 1 in the list.","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[1;32m/home/jyzhao/Code/Datasets/myLoader/myUtils/DatasetTester.ipynb Cell 6\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jyzhao/Code/Datasets/myLoader/myUtils/DatasetTester.ipynb#W5sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m writer \u001b[39m=\u001b[39m SummaryWriter(\u001b[39m'\u001b[39m\u001b[39mruns/dataset_visualization\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jyzhao/Code/Datasets/myLoader/myUtils/DatasetTester.ipynb#W5sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m300\u001b[39m):\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jyzhao/Code/Datasets/myLoader/myUtils/DatasetTester.ipynb#W5sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m         \u001b[39m#sampler.set_epoch(epoch)\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/jyzhao/Code/Datasets/myLoader/myUtils/DatasetTester.ipynb#W5sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m         \u001b[39mfor\u001b[39;00m i, data \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(dataloader):\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jyzhao/Code/Datasets/myLoader/myUtils/DatasetTester.ipynb#W5sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m                 \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m, end\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n","File \u001b[0;32m~/anaconda3/envs/torch210/lib/python3.9/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    631\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n","File \u001b[0;32m~/anaconda3/envs/torch210/lib/python3.9/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n","File \u001b[0;32m~/anaconda3/envs/torch210/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n","File \u001b[0;32m~/anaconda3/envs/torch210/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n","File \u001b[0;32m~/Code/Datasets/myLoader/myUtils/newX1000loader.py:84\u001b[0m, in \u001b[0;36mX4K1000FPSDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     82\u001b[0m gt \u001b[39m=\u001b[39m gt\u001b[39m.\u001b[39mpermute(\u001b[39m2\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[1;32m     83\u001b[0m timestep \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mfull_like(img0, timestep)\n\u001b[0;32m---> 84\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mcat((img0, img1, gt), \u001b[39m0\u001b[39;49m), timestep\n","\u001b[0;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 0. Expected size 224 but got size 223 for tensor number 1 in the list."]}],"source":["# TensorBoard Setup\n","writer = SummaryWriter('runs/dataset_visualization')\n","for epoch in range(300):\n","        #sampler.set_epoch(epoch)\n","        for i, data in enumerate(dataloader):\n","                print(\".\", end=\"\")"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"ename":"UnboundLocalError","evalue":"local variable 'h' referenced before assignment","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)","\u001b[1;32m/home/jyzhao/Code/Datasets/myLoader/myUtils/DatasetTester.ipynb Cell 5\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jyzhao/Code/Datasets/myLoader/myUtils/DatasetTester.ipynb#W4sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m writer \u001b[39m=\u001b[39m SummaryWriter(\u001b[39m'\u001b[39m\u001b[39mruns/dataset_visualization\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jyzhao/Code/Datasets/myLoader/myUtils/DatasetTester.ipynb#W4sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Fetch a batch of data\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/jyzhao/Code/Datasets/myLoader/myUtils/DatasetTester.ipynb#W4sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m images \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(\u001b[39miter\u001b[39;49m(dataloader))[\u001b[39m0\u001b[39m]  \u001b[39m# Get the first batch and extract the image stack\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jyzhao/Code/Datasets/myLoader/myUtils/DatasetTester.ipynb#W4sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# Log images to TensorBoard\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jyzhao/Code/Datasets/myLoader/myUtils/DatasetTester.ipynb#W4sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m writer\u001b[39m.\u001b[39madd_images(\u001b[39m'\u001b[39m\u001b[39msample_images\u001b[39m\u001b[39m'\u001b[39m, images, \u001b[39m0\u001b[39m)\n","File \u001b[0;32m~/anaconda3/envs/torch210/lib/python3.9/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    631\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n","File \u001b[0;32m~/anaconda3/envs/torch210/lib/python3.9/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n","File \u001b[0;32m~/anaconda3/envs/torch210/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n","File \u001b[0;32m~/anaconda3/envs/torch210/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n","File \u001b[0;32m~/Code/Datasets/myLoader/myUtils/newX1000loader.py:52\u001b[0m, in \u001b[0;36mX4K1000FPSDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     50\u001b[0m     h, w \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcrop_size\n\u001b[1;32m     51\u001b[0m images \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform(image) \u001b[39mfor\u001b[39;00m image \u001b[39min\u001b[39;00m images]\n\u001b[0;32m---> 52\u001b[0m img0 \u001b[39m=\u001b[39m crop(images[\u001b[39m0\u001b[39m],h,w)\n\u001b[1;32m     53\u001b[0m gt \u001b[39m=\u001b[39m crop(images[\u001b[39m1\u001b[39m],h,w)\n\u001b[1;32m     54\u001b[0m img1 \u001b[39m=\u001b[39m crop(images[\u001b[39m2\u001b[39m],h,w)\n","\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'h' referenced before assignment"]}],"source":["# TensorBoard Setup\n","writer = SummaryWriter('runs/dataset_visualization')\n","\n","# Fetch a batch of data\n","images = next(iter(dataloader))[0]  # Get the first batch and extract the image stack\n","\n","# Log images to TensorBoard\n","writer.add_images('sample_images', images, 0)\n","writer.close()\n","print('Images logged to TensorBoard.')\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":4}
